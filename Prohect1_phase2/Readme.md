Training model using pretrained word embeddings <br />
Train on 8000 samples, validate on 10000 samples <br />
Epoch 1/10 <br />
8000/8000 [==============================] - 1s 80us/step - loss: 0.1848 - acc: 0.9460 - val_loss: 1.2929 - val_acc: 0.6704 <br />
Epoch 2/10
8000/8000 [==============================] - 0s 50us/step - loss: 0.1790 - acc: 0.9436 - val_loss: 1.2958 - val_acc: 0.6728 <br />
Epoch 3/10
8000/8000 [==============================] - 0s 50us/step - loss: 0.1752 - acc: 0.9457 - val_loss: 1.2752 - val_acc: 0.6715 <br />
Epoch 4/10
8000/8000 [==============================] - 0s 38us/step - loss: 0.1710 - acc: 0.9480 - val_loss: 1.1804 - val_acc: 0.6707 <br />
Epoch 5/10
8000/8000 [==============================] - 0s 41us/step - loss: 0.1717 - acc: 0.9489 - val_loss: 1.3768 - val_acc: 0.6755 <br />
Epoch 6/10
8000/8000 [==============================] - 0s 42us/step - loss: 0.1721 - acc: 0.9476 - val_loss: 1.5451 - val_acc: 0.6732 <br />
Epoch 7/10
8000/8000 [==============================] - 0s 39us/step - loss: 0.1769 - acc: 0.9464 - val_loss: 1.2589 - val_acc: 0.6679 <br />
Epoch 8/10
8000/8000 [==============================] - 0s 39us/step - loss: 0.1674 - acc: 0.9489 - val_loss: 1.3063 - val_acc: 0.6697 <br />
Epoch 9/10
8000/8000 [==============================] - 0s 45us/step - loss: 0.1634 - acc: 0.9517 - val_loss: 1.4411 - val_acc: 0.6712 <br />
Epoch 10/10
8000/8000 [==============================] - 0s 38us/step - loss: 0.1726 - acc: 0.9483 - val_loss: 1.3236 - val_acc: 0.6715 <br />

 
![alt text](https://github.com/krishnagorrepati/DeepLearningProjects/blob/master/Training_and_Validation_Accuracy.jpeg)

![alt text](https://github.com/krishnagorrepati/DeepLearningProjects/blob/master/Training_and_Validation_Loss.jpeg)

 
